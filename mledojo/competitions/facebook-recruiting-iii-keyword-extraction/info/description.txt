### Description

Join Facebook in their quest to discover top data scientists and software engineers through this exciting Kaggle competition! Building on the success of previous contests, this third installment challenges participants to showcase their text mining skills using a substantial dataset from Stack Exchange. Your task is to predict tags (keywords, topics, summaries) based solely on the question text and title. The dataset features a diverse array of technical and non-technical questions from various Stack Exchange sites.

Candidates are encouraged to apply for positions in Menlo Park, Seattle, New York City, and London, and must have or be eligible to obtain authorization to work in the US or UK. Remember, this is an individual competition, and using external resources to find answers is prohibited. Facebook will review the code of top participants for potential interview opportunities. To be considered for an interview, ensure you check the box "Allow host to contact me" when submitting your first entry.

### Evaluation

The evaluation metric for this competition is Mean F1-Score. The F1 score, commonly used in information retrieval, measures accuracy using the statistics precision p and recall r. Precision is the ratio of true positives (tp) to all predicted positives (tp + fp). Recall is the ratio of true positives to all actual positives (tp + fn). The F1 score is given by:

F1 = 2\frac{p \cdot r}{p+r}\ \ \mathrm{where}\ \ p = \frac{tp}{tp+fp},\ \ r = \frac{tp}{tp+fn}

The F1 metric weights recall and precision equally, and a good retrieval algorithm will maximize both precision and recall simultaneously. Thus, moderately good performance on both will be favored over extremely good performance on one and poor performance on the other.

To receive credit, the tag you predict must be an exact match, regardless of whether you believe the tags are synonyms. Why aren't synonyms counted?

### Submission File

For every question in the test set, your submission file should contain two columns: Id and Tags. Id is the unique identifier of a question in test.csv. Tags should be a space-delimited list predicted tags. You should maintain the order of questions.

The file should contain a header and have the following format:

```
Id,Tags
1,"c++ javaScript"
2,"php python mysql"
3,"django"
etc.
```

### Dataset Description

All of the data is in 2 files: Train and Test.

Train.csv contains 4 columns: Id, Title, Body, Tags

- Id - Unique identifier for each question
- Title - The question's title
- Body - The body of the question
- Tags - The tags associated with the question (all lowercase, should not contain tabs '\t' or ampersands '&')

Test.csv contains the same columns but without the Tags, which you are to predict.

The questions are randomized and contain a mix of verbose text sites as well as sites related to math and programming. The number of questions from each site may vary, and no filtering has been performed on the questions (such as closed questions).

### Files

- Train.csv
- Test.csv

### Other Important Information

This competition counts towards rankings & achievements.