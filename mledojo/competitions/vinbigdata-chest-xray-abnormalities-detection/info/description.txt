### Description

In this competition, participants will tackle the challenge of automatically localizing and classifying 14 types of thoracic abnormalities from chest radiographs. Radiologists often face difficulties interpreting chest X-rays, which can lead to misdiagnoses. By developing computer-aided detection and diagnosis systems (CADe/CADx), this competition aims to alleviate the burden on doctors in busy metropolitan hospitals and enhance diagnostic accuracy in rural settings. 

The dataset consists of 18,000 annotated scans, with 15,000 images available for training and a test set of 3,000 images. These annotations were meticulously collected by experienced radiologists through VinBigData's platform, VinLab. Successful models will provide valuable second opinions for radiologists, improving patient outcomes through more accurate diagnoses.

### Evaluation

The challenge uses the standard PASCAL VOC 2010 mean Average Precision (mAP) at IoU > 0.4.

## Submission File

Images in the test set may contain more than one object. For each object in a given test image, you must predict a class ID, confidence score, and bounding box in format xmin ymin xmax ymax. If you predict that there are NO objects in a given image, you should predict 14 1.0 0 0 1 1, where 14 is the class ID for "No finding", 1.0 is the confidence, and 0 0 1 1 is a one-pixel bounding box.

The submission file should contain a header and have the following format:

```
ID,TARGET
004f33259ee4aef671c2b95d54e4be68,14 1 0 0 1 1
004f33259ee4aef671c2b95d54e4be69,11 0.5 100 100 200 200 13 0.7 10 10 20 20
etc.
```

### Dataset Description

In this competition, we are classifying common thoracic lung diseases and localizing critical findings. This is an object detection and classification problem.

For each test image, you will be predicting a bounding box and class for all findings. If you predict that there are no findings, you should create a prediction of "14 1 0 0 1 1" (14 is the class ID for no finding, and this provides a one-pixel bounding box with a confidence of 1.0).

The images are in DICOM format, which means they contain additional data that might be useful for visualizing and classifying.

## Dataset information

The dataset comprises 18,000 postero-anterior (PA) CXR scans in DICOM format, which were de-identified to protect patient privacy. All images were labeled by a panel of experienced radiologists for the presence of 14 critical radiographic findings as listed below:

```
0 - Aortic enlargement
1 - Atelectasis
2 - Calcification
3 - Cardiomegaly
4 - Consolidation
5 - ILD
6 - Infiltration
7 - Lung Opacity
8 - Nodule/Mass
9 - Other lesion
10 - Pleural effusion
11 - Pleural thickening
12 - Pneumothorax
13 - Pulmonary fibrosis
```

The "No finding" observation (14) was intended to capture the absence of all findings above.

Note that a key part of this competition is working with ground truth from multiple radiologists.

## Files

- train.csv - the train set metadata, with one row for each object, including a class and a bounding box. Some images in both test and train have multiple objects.
- sample_submission.csv - a sample submission file in the correct format

## Columns

- image_id - unique image identifier
- class_name - the name of the class of detected object (or "No finding")
- class_id - the ID of the class of detected object
- rad_id - the ID of the radiologist that made the observation
- x_min - minimum X coordinate of the object's bounding box
- y_min - minimum Y coordinate of the object's bounding box
- x_max - maximum X coordinate of the object's bounding box
- y_max - maximum Y coordinate of the object's bounding box

### Other Important Information

Participants are strictly prohibited from hand-labeling the test set, including using any hand-labeling of the test set to inform model training or selection. The host will thoroughly review winning teams' full source code, and any team found violating this rule will be disqualified.