### Description

Join the fight against diabetic retinopathy, a leading cause of blindness among working-age adults. This competition, hosted by Aravind Eye Hospital in India, aims to enhance the detection and prevention of this disease in rural areas where medical screenings are challenging. By developing a machine learning model to automatically analyze thousands of retinal images, participants will help improve the hospital's diagnostic capabilities and potentially extend these solutions to other ophthalmologists through the 4th Asia Pacific Tele-Ophthalmology Society (APTOS) Symposium.

Currently, Aravind technicians travel to remote locations to capture images, which are then reviewed by trained doctors. The goal is to leverage technology to automate this process, enabling quicker and more accurate disease detection. Successful models may also pave the way for identifying other conditions, such as glaucoma and macular degeneration. Get started today and contribute to preventing lifelong blindness!

### Evaluation

Submissions are scored based on the quadratic weighted kappa, which measures the agreement between two ratings. This metric typically varies from 0 (random agreement between raters) to 1 (complete agreement between raters). In the event that there is less agreement between the raters than expected by chance, this metric may go below 0. The quadratic weighted kappa is calculated between the scores assigned by the human rater and the predicted scores.

Images have five possible ratings, 0,1,2,3,4. Each image is characterized by a tuple (e,e), which corresponds to its scores by Rater A (human) and Rater B (predicted). The quadratic weighted kappa is calculated as follows. First, an N x N histogram matrix O is constructed, such that O corresponds to the number of images that received a rating i by A and a rating j by B. An N-by-N matrix of weights, w, is calculated based on the difference between raters' scores:

An N-by-N histogram matrix of expected ratings, E, is calculated, assuming that there is no correlation between rating scores. This is calculated as the outer product between each rater's histogram vector of ratings, normalized such that E and O have the same sum.

Submissions should be formatted like:

```
id_code,diagnosis
0005cfc8afb6,0
003f0afdcd15,0
etc.
```

### Submission File

### Dataset Description

You are provided with a large set of retina images taken using fundus photography under a variety of imaging conditions.

A clinician has rated each image for the severity of diabetic retinopathy on a scale of 0 to 4:

0 - No DR

1 - Mild

2 - Moderate

3 - Severe

4 - Proliferative DR

Like any real-world data set, you will encounter noise in both the images and labels. Images may contain artifacts, be out of focus, underexposed, or overexposed. The images were gathered from multiple clinics using a variety of cameras over an extended period of time, which will introduce further variation.

### Files

In a synchronous Kernels-only competition, the files you can observe and download will be different than the private test set and sample submission. The files may have different ids, may be a different size, and may vary in other ways, depending on the problem. You should structure your code so that it returns predictions for the public test set images in the format specified by the public sample_submission.csv, but does not hard code aspects like the id or number of rows. When Kaggle runs your Kernel privately, it substitutes the private test set and sample submission in place of the public ones. You can plan on the private test set consisting of 20GB of data across 13,000 images (approximately).

- train.csv - the training labels
- test.csv - the test set (you must predict the diagnosis value for these variables)
- sample_submission.csv - a sample submission file in the correct format
- train.zip - the training set images
- test.zip - the public test set images

### Other Important Information

This is a Kernels-only competition. Submissions must be made through Kernels, which will automatically re-run against an unseen test set and output a file named submission.csv. Ensure your kernel meets the runtime and internet requirements for submission.